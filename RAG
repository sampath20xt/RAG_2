from pymongo import MongoClient
from sentence_transformers import SentenceTransformer
import chromadb
import os
import vertexai
from vertexai.preview.generative_models import GenerativeModel
from vertexai.generative_models import HarmCategory, HarmBlockThreshold

# Initialize MongoDB
mongo_url = "mongodb+srv://admin:Sampath@cluster01.wcpmehz.mongodb.net/"
mongo_client = MongoClient(mongo_url)
db = mongo_client["RAG"]

# Collections
collections = ["articles", "careers", "practices", "teams"]

# Extract schema information
schema_info = {}
for collection_name in collections:
    collection = db[collection_name]
    first_document = collection.find_one()
    if first_document:
        schema_info[collection_name] = list(first_document.keys())

# Print extracted schema information
print("Schema Information:", schema_info)

# Initialize ChromaDB
chroma_client = chromadb.Client()
chroma_collection = chroma_client.create_collection(name="BOTcollection")
print("Created the collection in ChromaDB")

# Populate ChromaDB with table embeddings
model = SentenceTransformer('multi-qa-distilbert-cos-v1')
for collection_name, columns in schema_info.items():
    embedding = model.encode(collection_name)
    chroma_collection.add(
        embeddings=[embedding],
        metadatas=[{"table_name": collection_name, "columns": ", ".join(columns)}],  # Convert list to string
        ids=[collection_name]
    )
print("Stored Tables in ChromaDB:", chroma_collection.get()["metadatas"])

# Initialize Google Vertex AI
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "email-extraction-381718-3f73208ce3b71.json"
vertexai.init(project="email-extraction-381718", location="us-central1")
generative_multimodal_model = GenerativeModel("gemini-1.5-pro-001")

# Function to generate embeddings
def generate_embedding(text):
    return model.encode(text)

# Function to find the most similar table
def similar_table(query):
    query_embedding = generate_embedding(query)
    results = chroma_collection.query(query_embeddings=[query_embedding], n_results=1)
    return results["metadatas"]

# Function to run a MongoDB query
def run_query(mongo_query):
    try:
        # Parse the table name from the query (e.g., "FROM practices")
        table_name = mongo_query.split("FROM")[1].split()[0].strip()
        
        # Extract the fields and filter conditions
        projection = {}
        filters = {}
        
        # Parse SELECT fields (e.g., "SELECT leaders")
        if "SELECT" in mongo_query:
            fields = mongo_query.split("SELECT")[1].split("FROM")[0].strip().split(",")
            projection = {field.strip(): 1 for field in fields}
        
        # Parse WHERE condition (e.g., "WHERE title = 'Administrative law'")
        if "WHERE" in mongo_query:
            condition = mongo_query.split("WHERE")[1].strip()
            field, value = condition.split("=")
            filters[field.strip()] = value.strip().strip("'")
        
        # Query the corresponding collection in MongoDB
        collection = db[table_name]
        result = collection.find(filters, projection)
        
        # Convert results to a list of dictionaries
        result_list = [doc for doc in result]
        return result_list
    except Exception as e:
        return {"error": str(e)}

# Function to generate a query using Vertex AI
def get_response(query, schema_info):
    prompt = f"""
    You are a data analyst at a company. You are interacting with a user who is asking you questions about the company's database.
    Your role is to generate the query to the user's question based on the schema_info given below.
    The schema info is in keys values pair where keys are table names and values are column names.
    Generate the query using those tables and column names from the given schema info.
    Take the conversation history into account.
    Write only the query and nothing else. Do not wrap the query in any other text, not even backticks.

    Schema information:
    {schema_info}

    User query: {query}
    """
    generation_config = {
        "max_output_tokens": 8192,
        "temperature": 0.3,
        "top_p": 0.5,
    }

    safety_settings = {
        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,
        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,
        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,
    }

    response = generative_multimodal_model.generate_content([prompt],
                                                            generation_config=generation_config,
                                                            safety_settings=safety_settings)
    return response.text.strip()

# Main workflow
user_question = "Who are the leaders of the title Administrative law?"
print("User Question:", user_question)

# Find the most relevant table
relative_table = similar_table(user_question)
print("Most Relevant Table:", relative_table)

# Generate MongoDB query using schema info
response_query = get_response(user_question, schema_info)
print("Generated Query:", response_query)

# Run the MongoDB query and print results
result = run_query(response_query)
print("Query Result:")
if isinstance(result, list):  # If the query returns documents
    for row in result:
        print(row)
else:  # If the query returns an error
    print(result)
